{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef039d5-79c4-4381-8070-038a2898f835",
   "metadata": {},
   "outputs": [],
   "source": [
    "%region us-east-1\n",
    "%iam_role # setar \n",
    "%idle_timeout 30\n",
    "%glue_version 4.0\n",
    "%worker_type G.1X\n",
    "%number_of_workers 5\n",
    "\n",
    "#%additional_python_modules s3://fiocruz-datalake-bucket/raw/aesop/dados_auxiliares/python_utils/teste.py\n",
    "%extra_py_files s3://fiocruz-datalake-bucket/raw/aesop/dados_auxiliares/python_utils/util_custom.py\n",
    "%additional_python_modules s3://fiocruz-datalake-bucket/raw/aesop/dados_auxiliares/epiweeks-2.3.0-py3-none-any.whl\n",
    "\n",
    "\n",
    "import sys\n",
    "from awsglue.transforms import *\n",
    "from awsglue.utils import getResolvedOptions\n",
    "from pyspark.context import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.job import Job\n",
    "  \n",
    "sc = SparkContext.getOrCreate()\n",
    "glueContext = GlueContext(sc)\n",
    "spark = glueContext.spark_session\n",
    "job = Job(glueContext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede261c2-76c9-4199-b0c1-62186e893694",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util_custom import *\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql.window import Window\n",
    "from epiweeks import Week\n",
    "\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "def create_folder_in_specific_location(bucket_name, full_folder_path):\n",
    "    # Adiciona uma barra ao final do caminho da pasta, se não houver\n",
    "    if not full_folder_path.endswith('/'):\n",
    "        full_folder_path += '/'\n",
    "    \n",
    "    s3 = boto3.resource('s3')\n",
    "    bucket = s3.Bucket(bucket_name)\n",
    "    \n",
    "    # Verifica se a pasta já existe\n",
    "    objs = list(bucket.objects.filter(Prefix=full_folder_path))\n",
    "    if any(obj.key == full_folder_path for obj in objs):\n",
    "        print(f\"A pasta '{full_folder_path}' já existe no bucket '{bucket_name}'.\")\n",
    "    else:\n",
    "        # Tenta criar a pasta (objeto S3 com chave terminando em '/')\n",
    "        try:\n",
    "            s3.Object(bucket_name, full_folder_path).put(Body=b'')\n",
    "            print(f\"Pasta '{full_folder_path}' criada com sucesso no bucket '{bucket_name}'.\")\n",
    "        except ClientError as e:\n",
    "            print(f\"Erro ao criar a pasta: {e}\")\n",
    "\n",
    "\n",
    "def list_all_files_in_folders_s3(bucket_name, prefix):\n",
    "    \"\"\"\n",
    "    Lista todos os arquivos dentro de todas as subpastas de um prefixo específico em um bucket S3.\n",
    "\n",
    "    :param bucket_name: Nome do bucket S3.\n",
    "    :param prefix: Prefixo dentro do bucket onde as subpastas estão localizadas.\n",
    "    :return: Uma lista de nomes de arquivos dentro de todas as subpastas sob o prefixo especificado.\n",
    "    \"\"\"\n",
    "    s3 = boto3.client('s3')\n",
    "    all_files = []\n",
    "\n",
    "    # Garante que o prefixo termine com uma barra, se já não terminar.\n",
    "    if not prefix.endswith('/'):\n",
    "        prefix += '/'\n",
    "\n",
    "    # Lista todas as 'subpastas' dentro do prefixo.\n",
    "    response = s3.list_objects_v2(Bucket=bucket_name, Prefix=prefix, Delimiter='/')\n",
    "\n",
    "    subfolders = []\n",
    "    if 'CommonPrefixes' in response:\n",
    "        for folder in response['CommonPrefixes']:\n",
    "            subfolders.append(folder['Prefix'])\n",
    "\n",
    "    # Para cada subpasta, lista todos os arquivos dentro dela.\n",
    "    for folder_name in subfolders:\n",
    "        resp = s3.list_objects_v2(Bucket=bucket_name, Prefix=folder_name)\n",
    "        if 'Contents' in resp:\n",
    "            for file in resp['Contents']:\n",
    "                # Adiciona o nome do arquivo à lista\n",
    "                all_files.append(file['Key'])\n",
    "    data_max = sorted(all_files)[-1][-12:-4]\n",
    "    return data_max\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Exemplo de uso\n",
    "bucket_name = 'fiocruz-datalake-bucket'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115c00a1-6172-49e5-a147-4a8323957f7c",
   "metadata": {},
   "source": [
    "#### leitura banco HPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb759ba-4486-41a0-a272-2ba4e6c065cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#aesop_2017_2024 = spark.read.parquet(aesop_hpc_path+get_hpc_parquet_file_name())\n",
    "#aesop_hpc_path+get_hpc_parquet_file_name()\n",
    "# aesop_2017_2024 = spark.read.parquet('/dados10t/datalake/standard/aesop/aesop_hpc/2017_20240107_AESOP.parquet/')\n",
    "\n",
    "aesop_2017_2024 = spark.read.parquet(\"s3://fiocruz-datalake-bucket/standard/output_hpc/2017_20240407_AESOP.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f14ee7-4f05-4793-bb19-9c91f7773e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ano = aesop_2017_2024.agg(F.max(\"ano\")).collect()[0][0]\n",
    "semana_folder = aesop_2017_2024.filter(F.col(\"ano\") == max_ano).agg(F.max(\"epiweek\")).collect()[0][0]\n",
    "semana_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dd492d-7ec4-4407-84d4-7b8e535902d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "aesop_report_folder  = \"standard/reports/report_dqi/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993b2bb3-9ff4-4d99-892e-dd378674712e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#caminho_pasta = aesop_report_folder+\"semana_\"+str(semana_folder)+\"_\"+str(max_ano)\n",
    "#caminho_pasta\n",
    "#create_folder_in_specific_location(bucket_name,caminho_pasta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753b4c80-709a-477b-86ac-4d1e8cf2282f",
   "metadata": {},
   "source": [
    "#### leitura banco raw parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1189f3bc-cfcc-4741-a528-3cd04dedd93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = spark.read.parquet(aesop_parquet_path+get_parquet_file_name())\n",
    "#aesop_parquet_path+get_parquet_file_name()\n",
    "# df = spark.read.parquet('/dados10t/datalake/raw/aesop/parquet_explorer/aesop_dados_2017_20240107.parquet/')\n",
    "df = spark.read.parquet(\"s3://fiocruz-datalake-bucket/raw/aesop/dados-ms-parquet/aesop_dados_2017_20240407.parquet/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ff3a08-5493-48cf-ae05-f9bea4941847",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter((F.col(\"FX_ETARIA\")).isNotNull())\n",
    "df_v2 = df.select(\"ANO\",\"SEMANA\",\"SG_UF\",\"CO_MUNICIPIO_IBGE\",\"SEXO\",\"FX_ETARIA\",\"CIDCIAP\",\"QT\",\"Data_folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6229610-e74d-4a9a-a6c2-e7c758cd3f3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df_v2.filter(F.col(\"ANO\") == 2023).show(5000,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1229dc38-4ef0-4df7-9e70-455b6b48bb95",
   "metadata": {},
   "source": [
    "#### converter cid_ciap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471aabbd-f3e2-45e8-ae4e-94527757d6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v3 = df_v2\\\n",
    ".withColumn(\"Tipo_CIDCIAP\", F.substring_index(df_v2.CIDCIAP, '(', 1))\\\n",
    ".withColumn(\"Codigo_CIDCIAP\", F.substring_index(df_v2.CIDCIAP, '(', -1))\n",
    "\n",
    "df_v3 = df_v3.withColumn('Codigo_CIDCIAP', F.concat(F.lit(\"(\"), F.col('Codigo_CIDCIAP')))\n",
    "\n",
    "# CIAP(R05) -> CIAP|(R05)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf26309e-88ed-4540-8e93-c5212756de6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" sisab_diff.show()\n",
    "+----+------+-----+-----------------+-----------+--------+\n",
    "| ANO|SEMANA|SG_UF|CO_MUNICIPIO_IBGE|Data_folder|qt_total|\n",
    "+----+------+-----+-----------------+-----------+--------+\n",
    "|2023|    32|   RS|           431490| 2023-12-31|       7|\n",
    "|2023|    37|   PR|           411850| 2023-12-31|      18|\n",
    "\"\"\"\n",
    "# OBS: max semana folder passa da epiweek\n",
    "\n",
    "sisab_diff = df_v3.groupBy(\"ANO\", \"SEMANA\", \"SG_UF\", \"CO_MUNICIPIO_IBGE\", \"Data_folder\").agg(F.sum(\"QT\").alias(\"qt_total\")).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31983061-d546-47da-b4be-3aa8e7e35eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sisab_diff.write.parquet(caminho_resultado+\"sisabdiff_dqi_\"+get_latest_date_aesop()+\".parquet\")\n",
    "#caminho_resultado+\"sisabdiff_dqi_\"+get_latest_date_aesop()+\".parquet\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9451cef8-13c8-4e11-b10b-e5cffa121c7a",
   "metadata": {},
   "source": [
    "#### gerar dados report dqi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7afc31-aa52-4c27-bef5-89a59390a9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ibge_munic = spark.read.csv('s3://fiocruz-datalake-bucket/raw/aesop/dados_auxiliares/ibge_municipios.csv', header=True, sep=';').drop('_c0')\n",
    "\n",
    "\"\"\" semanas_epis.show()\n",
    "+------+----+-------+-----------------+--------------------+--------+----------+\n",
    "|SEMANA| ANO|uf_ibge|CO_MUNICIPIO_IBGE|           municipio|pop_2010|     porte|\n",
    "+------+----+-------+-----------------+--------------------+--------+----------+\n",
    "|    23|2024|     BA|           290590|Campo Alegre de L...|   28090|Pequeno II|\n",
    "|    24|2017|     BA|           290590|Campo Alegre de L...|   28090|Pequeno II|\n",
    "\"\"\"\n",
    "\n",
    "#semanas_epis = spark.read.parquet(\"s3://fiocruz-datalake-bucket/raw/aesop/dados_auxiliares/epiweek_ibge2017_20241231.parquet/\")\n",
    "semanas_epis = spark.read.csv(\"s3://fiocruz-datalake-bucket/raw/aesop/dados_auxiliares/epiweek_ibge2017_20241231.csv\",header=True)\n",
    "semanas_epis = semanas_epis.withColumnRenamed(\"semana_ibge\", \"SEMANA\")\n",
    "semanas_epis = semanas_epis.withColumnRenamed(\"ano_ibge\", \"ANO\")\n",
    "semanas_epis = semanas_epis.withColumnRenamed(\"co_ibge\", \"CO_MUNICIPIO_IBGE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ce3118-1647-4b40-9919-73dd4edf155b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#semanas_epis.count() #2328260"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01fbf60-4f73-4917-835d-48f326333aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#semanas_epis.select(\"CO_MUNICIPIO_IBGE\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7f39b9-02ad-42c3-880b-4e75ad5c85ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" sisab_diff.show() max dt_encounter 2023\n",
    "+----+------+-----+-----------------+-----------+--------+-----------------+------------+\n",
    "| ANO|SEMANA|SG_UF|CO_MUNICIPIO_IBGE|Data_folder|qt_total|first_day_of_year|dt_encounter|\n",
    "+----+------+-----+-----------------+-----------+--------+-----------------+------------+\n",
    "|2023|    52|   RS|           430830| 2023-12-27|      28|       2023-01-01|  2023-12-30|\n",
    "|2023|    52|   BA|           292840| 2023-12-29|      86|       2023-01-01|  2023-12-30|\n",
    "\"\"\"\n",
    "\n",
    "# Adicionando uma nova coluna com a data do primeiro dia do ano\n",
    "sisab_diff = sisab_diff.withColumn(\"first_day_of_year\", F.expr(\"make_date(ano, 1, 1)\"))\n",
    "\n",
    "# Calculando de forma estimada a data do atendimento a partir da variável semana usando a formula : 01/01/ano + numero de dias da formula:  (semana * 7) -1\n",
    "sisab_diff = sisab_diff.withColumn(\"dt_encounter\", F.expr(\"date_add(first_day_of_year, semana * 7 - 1)\"))\n",
    "\n",
    "# TODO run this only for 2024\n",
    "sisab_diff = sisab_diff\\\n",
    ".withColumn(\"dt_encounter\", F.when(F.col('ANO') == 2024, F.expr(\"date_add(first_day_of_year, semana * 7 - 2)\")).otherwise(F.expr(\"date_add(first_day_of_year, semana * 7 - 1)\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205a99d4-b878-4511-a7f4-3983fb3d43e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dt_folder é criado a partir da variável data_folder, é um arredondamento dessa data para o proximo sabado usando a formula , data_folde + n dias(proximo domingo - 1)\n",
    "sisab_diff = sisab_diff.withColumn(\"dt_folder\", F.expr(\"date_add(next_day(data_folder, 'Sun'), -1)\")) \n",
    "\n",
    "#diferença em dias de dt_folder para dt_encounter\n",
    "sisab_diff = sisab_diff.withColumn(\"date_diff\", F.datediff(\"dt_folder\",\"dt_encounter\") ) \n",
    "\n",
    "#diff de semanas entre atendimento estimado e data do envio\n",
    "sisab_diff = sisab_diff.withColumn(\"week_diff\", F.col(\"date_diff\") / 7 )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27582f3-b582-4002-8cd5-6fb292195702",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sisab_diff.filter(F.col(\"ANO\") == 2019).filter(F.col(\"SEMANA\") == 52).show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088e61f6-61e6-4d8a-8b6b-0b2d2967330f",
   "metadata": {},
   "source": [
    "#### calcular filtros de 8 semanas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f666459-a8df-4d28-b937-cf3b0e75d34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#semana_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85306b7b-e2c4-4c7f-b858-8e276ff7a8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "semana_filter = semana_folder-7\n",
    "ano_filter = max_ano\n",
    "if semana_filter < 1:\n",
    "    ano_filter = ano_filter-1\n",
    "    semana_filter = 52+semana_filter\n",
    "    \n",
    "print(semana_filter)\n",
    "print(ano_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a33663-687d-4125-b1c9-dd786bd7ac19",
   "metadata": {},
   "outputs": [],
   "source": [
    "semana_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ebd85c-d16b-4b61-9f87-5fd87ec22aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sisab_diff.filter(F.col('ANO') == ano_filter).filter(F.col('SEMANA') == semana_filter).select(\"dt_encounter\").distinct().count() #aqui tem somente 1 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e60d3b-d688-4c63-90fe-6885244b72da",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_date = sisab_diff.filter(F.col('ANO') == ano_filter)\\\n",
    ".filter(F.col('SEMANA') == semana_filter)\\\n",
    ".select(F.max(F.col('dt_encounter')) ).collect()[0][0]\n",
    "print(filter_date) #2024-01-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323a04bc-4ee0-40f4-8da4-2f6d4e9b66bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sisab_diff.filter(sisab_diff['dt_encounter'] >= filter_date).select(\"SEMANA\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6294e3d-7cfa-4bc6-967b-3bcbf2323d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#completude.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589f5237-9dd3-4897-8bd3-543c283f4852",
   "metadata": {},
   "source": [
    "#### completude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e0795c-de26-49a3-ad4b-9db5111cfc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `df` is your Spark DataFrame equivalent to `sisab_diff`\n",
    "# and `week_filter` is already defined\n",
    "\n",
    "#week_filter = \"2023-01-07\"\n",
    "\n",
    "# Step 1: Filter based on `dt_folder`\n",
    "completude = sisab_diff.filter(sisab_diff['dt_encounter'] >= filter_date)\n",
    "\n",
    "# Step 2: Select specific columns and remove others\n",
    "#tempestividade = tempestividade.drop('Data_folder', 'ANO', 'SEMANA', 'SG_UF')\n",
    "completude = completude\\\n",
    ".drop('Data_folder', 'ANO', 'SEMANA', 'SG_UF', 'first_day_of_year', 'date_diff')\\\n",
    ".withColumnRenamed('CO_MUNICIPIO_IBGE', 'co_ibge')\n",
    "\n",
    "# complete command\n",
    "ibge = completude.select('co_ibge').distinct()\n",
    "dt_encounter = completude.select('dt_encounter').distinct()\n",
    "ibge_dtencounter = ibge.crossJoin(dt_encounter)\n",
    "# complete join back\n",
    "completude = ibge_dtencounter.join(completude, ['co_ibge', 'dt_encounter'], 'left')\n",
    "\n",
    "\"\"\"\n",
    "completude.show()\n",
    "+-------+------------+----+\n",
    "|co_ibge|dt_encounter|   n|\n",
    "+-------+------------+----+\n",
    "| 150375|  2023-11-25| 351|\n",
    "| 150375|  2023-11-18| 336|\n",
    "\"\"\"\n",
    "\n",
    "# count \n",
    "completude = completude.groupBy('co_ibge', 'dt_encounter')\\\n",
    ".agg(F.sum('qt_total').alias('n'))\\\n",
    ".na.fill({'n': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b658469c-974a-418b-a6dd-eafbd8af0142",
   "metadata": {},
   "outputs": [],
   "source": [
    "semana_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19810f31-cb22-40a3-9de3-a94db55ac55c",
   "metadata": {},
   "source": [
    "#### completude porcentagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad677d2-1dd1-4c9c-a452-2da8251a7291",
   "metadata": {},
   "outputs": [],
   "source": [
    "ibge_munic.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22715bf7-4092-4727-9d19-ccb7039d026c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slider\n",
    "ws = Window.partitionBy(\"co_ibge\").orderBy(\"dt_encounter\").rowsBetween(-7, Window.currentRow)\n",
    "\n",
    "# UDF for epiweek and epiyear\n",
    "epiweekUDF = F.udf(lambda z:  Week.fromdate(z).week, IntegerType())\n",
    "epiyearUDF = F.udf(lambda z:  Week.fromdate(z).year, IntegerType())\n",
    "\n",
    "# slider as window function\n",
    "completude_missings = completude\\\n",
    ".withColumn(\"empty\", F.when(F.col('n')==0, 1).otherwise(0))\\\n",
    ".withColumn(\"window_size\", F.count(\"*\").over(ws))\\\n",
    ".withColumn(\"start\", F.min(\"dt_encounter\").over(ws))\\\n",
    ".withColumn(\"end\", F.max(\"dt_encounter\").over(ws))\\\n",
    ".withColumn(\"no_missings\", F.sum(\"empty\").over(ws))\\\n",
    ".filter(F.col('window_size')==8)\\\n",
    ".withColumn(\"epi_week\", epiweekUDF(F.col('dt_encounter')))\\\n",
    ".withColumn(\"epi_year\", epiyearUDF(F.col('dt_encounter')))\\\n",
    ".drop('window_size', 'empty', 'n', 'dt_encounter')\\\n",
    ".filter(F.col('epi_week')==semana_folder)\n",
    "\n",
    "# add missing cities \n",
    "completude_miss_ibge = ibge_munic.join(completude_missings, ['co_ibge'], 'full')\n",
    "\n",
    "# perc completude\n",
    "\"\"\"\n",
    "+-------+---+--------------------+--------+----------+----------+----------+-----------+--------+--------+------------+---------------+\n",
    "|co_ibge| uf|           municipio|pop_2010|     porte|     start|       end|no_missings|epi_week|epi_year|perc_missing|perc_completude|\n",
    "+-------+---+--------------------+--------+----------+----------+----------+-----------+--------+--------+------------+---------------+\n",
    "| 110001| RO|Alta Floresta D´o...|   24392|Pequeno II|2023-11-11|2023-12-30|          0|      52|    2023|         0.0|          100.0|\n",
    "| 110002| RO|           Ariquemes|   90353|     Médio|2023-11-11|2023-12-30|          1|      52|    2023|        12.5|           87.5|\n",
    "\"\"\"\n",
    "\n",
    "# calculate percentages\n",
    "comp_percentage = completude_miss_ibge.na.fill({'no_missings': 8})\\\n",
    ".withColumn('perc_missing',  F.col('no_missings')/8*100)\\\n",
    ".withColumn('perc_completude',  100-F.col('perc_missing'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1385f5e9-ad48-4f46-88e1-3642f52e1546",
   "metadata": {},
   "source": [
    "#### tempestividade "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9412fe-a27c-4833-8e7e-be6b5c4c48a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Filter based on `dt_folder`\n",
    "tempestividade = sisab_diff.filter( F.col(\"dt_folder\")  >= filter_date)\n",
    "\n",
    "# Step 2:dropa algumas colunas\n",
    "tempestividade = tempestividade.drop('Data_folder', 'ANO', 'SEMANA', 'SG_UF')\n",
    "\n",
    "# faz o complete dos dados levando em conta todas as possibilidades de CO_MUNICIPIO_IBGE x dt_folder\n",
    "co_ibge_df = tempestividade.select(\"CO_MUNICIPIO_IBGE\").distinct()\n",
    "dt_folder_df = tempestividade.select(\"dt_folder\").distinct()\n",
    "all_combinations_df = co_ibge_df.crossJoin(dt_folder_df)\n",
    "\n",
    "# faz o join para o lado completo criando anteriormente\n",
    "tempestividade2 = all_combinations_df.join(tempestividade, [\"CO_MUNICIPIO_IBGE\", \"dt_folder\"], \"left_outer\")\n",
    "\n",
    "#conta os atendimento para as 8 semanas de dados\n",
    "tempestividade3_p1 = tempestividade2.groupBy(\"CO_MUNICIPIO_IBGE\").agg(F.sum(\"qt_total\").alias(\"total_atd_folder\"))\n",
    "\n",
    "#faz categorias  a partir da diff em semanas entre atendimento e envio para as ultimas 8 semanas. se ate 2 semanas de diff,  0_2weeks , se maior que duas semanas, 3+weeks,soma-se o total de atendimento para cada categoria criada.\n",
    "tempestividade3_p2 = tempestividade2.withColumn(\"diff\", F.when(  F.col(\"week_diff\") <= 2, \"0_2weeks\").otherwise(\n",
    "                                                        F.when(   F.col(\"week_diff\") > 2, \"3+weeks\"  )    ) ) .groupBy(\"CO_MUNICIPIO_IBGE\",\"diff\").agg( F.sum(\"qt_total\").alias(\"qt_diff\") )\n",
    "\n",
    "#junta o atendimento total das 8 semanas com os atendimentos das 8 semanas categorizado entre 0_2weeks e   3+weeks\n",
    "tempestividade3 = tempestividade3_p1.join(tempestividade3_p2 , ['CO_MUNICIPIO_IBGE'])\n",
    "tempestividade3 = tempestividade3.withColumn(\"diff_percent\", F.col(\"qt_diff\") / F.col(\"total_atd_folder\") * 100)\n",
    "tempestividade3 = tempestividade3.withColumn(\"diff_percent2\",F.round(\"diff_percent\",5))\n",
    "\n",
    "#pivota os dados para as variáveis de porcetagem 0_2weeks e 3+weeks irem para colunas\n",
    "tempestividade4  = tempestividade3.groupBy(\"CO_MUNICIPIO_IBGE\").pivot(\"diff\").agg(F.first(\"diff_percent2\"))\n",
    "\n",
    "\"\"\" tempestividade5\n",
    "+--------+--------+-------+\n",
    "| diff_2w| diff_3w|co_ibge|\n",
    "+--------+--------+-------+\n",
    "|99.83987| 0.16013| 150300|\n",
    "|54.82866|45.17134| 150375|\n",
    "|   100.0|    null| 172015|\n",
    "\"\"\"\n",
    "\n",
    "tempestividade5 = tempestividade4.withColumnRenamed(\"0_2weeks\",\"diff_2w\")\n",
    "tempestividade5 = tempestividade5.withColumnRenamed(\"3+weeks\",\"diff_3w\")\n",
    "tempestividade5 = tempestividade5.withColumn(\"co_ibge\",F.col(\"CO_MUNICIPIO_IBGE\").cast(StringType() ) ).drop(\"CO_MUNICIPIO_IBGE\",\"diff_2w_new\",\"diff_3w_new\",\"null\").cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b05fa26-1a6b-4599-8ba2-dec1ae88a069",
   "metadata": {},
   "source": [
    "#### Atendimentos (atd) nas últimas semanas\n",
    "TODO: verificar filtro ano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de341648-d6a0-431f-a83c-1e7adcb40e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#agrupar os dados de \"ANO\",\"SEMANA\",\"SG_UF\",\"CO_MUNICIPIO_IBGE\" somando o qt_total\n",
    "df_agg = sisab_diff.groupBy(\"ANO\",\"SEMANA\",\"SG_UF\",\"CO_MUNICIPIO_IBGE\").agg(F.sum(\"qt_total\").alias(\"qt_total\")) \n",
    "\n",
    "#junta com os dados das semanas epidemiologicas completas, filtrando em seguida para dados ate 2023 e que a semana sejam somente as duas últimas, ou seja menor que a semana folder(semana atual) e maior que a semana folder - 1, ex: semana 47 seria de 46 a 47\n",
    "df_agg_v2 = semanas_epis.join(df_agg , [\"ANO\",\"SEMANA\",\"CO_MUNICIPIO_IBGE\"] , 'left')\n",
    "df_agg_v3 = df_agg_v2.filter(F.col(\"ANO\") == 2024)\n",
    "df_agg_v4 = df_agg_v3.filter(F.col(\"SEMANA\") <= semana_folder).filter(F.col(\"SEMANA\") >= semana_folder-1)  # capturar somente ate a semana atual , e somente maiores que a semana atual - 1 \n",
    "\n",
    "#para criar a variável sum_miss que tem 3 categorias, 0(com atendimentos nas 2 semanas) , 1 (com atendimento em somente 1 das duas semanas ) e 2 (sem atendimetnos nas duas semanas)\n",
    "windowSpec = Window.partitionBy(\"CO_MUNICIPIO_IBGE\")\n",
    "\n",
    "df_agg_v5 = df_agg_v4.withColumn(\"count_empty\", F.sum(F.when(F.col(\"qt_total\").isNull(), 1).otherwise(0)).over(windowSpec))\n",
    "df_agg_v6 = df_agg_v5.select(\"CO_MUNICIPIO_IBGE\",\"SEMANA\",\"ANO\",\"count_empty\").groupBy(\"CO_MUNICIPIO_IBGE\").agg(F.first(\"count_empty\").alias(\"sum_miss\"))\n",
    "df_agg_v7 = df_agg_v6.withColumn(\"co_ibge\",F.col(\"CO_MUNICIPIO_IBGE\").cast(IntegerType()).cast(StringType()) ).drop(\"CO_MUNICIPIO_IBGE\")\n",
    "\n",
    "dqi = df_agg_v7.join(tempestividade5,['co_ibge'],'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1937a872-7a5f-496f-92ba-be0004770509",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqi_v2 = dqi.join(comp_percentage,['co_ibge'],'left')\n",
    "\n",
    "dqi_v2 = dqi_v2.withColumn(\"tempestividade\",F.when(F.col(\"diff_2w\") >=  75,  0).otherwise(1)  )\n",
    "dqi_v2 = dqi_v2.withColumn(\"completude\",F.when(F.col(\"perc_completude\") >=  85, 0).otherwise(1)  )\n",
    "\n",
    "cond1 = F.col(\"completude\") == 0\n",
    "cond2 = F.col(\"tempestividade\") == 0\n",
    "cond3 = F.col(\"sum_miss\") == 0\n",
    "\n",
    "dqi_v2 = dqi_v2.withColumn(\"dqi\",F.when( cond1 & cond2 & cond3, \"Apto\").otherwise(\"Não Apto\")  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ad81eb-7595-4a9b-8228-da4ba3282050",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" dqi_v3.show()\n",
    "+---+-------+-------------------+--------+--------+------------+---------------+--------+--------+--------+----------+--------------+--------+\n",
    "| uf|co_ibge|          municipio|epi_week|epi_year|perc_missing|perc_completude| diff_2w| diff_3w|sum_miss|completude|tempestividade|     dqi|\n",
    "+---+-------+-------------------+--------+--------+------------+---------------+--------+--------+--------+----------+--------------+--------+\n",
    "| PA| 150200| Cachoeira do Arari|      52|    2023|        12.5|           87.5|32.79879|67.20121|       1|         0|             1|Não Apto|\n",
    "| PI| 220290|           Corrente|      52|    2023|         0.0|          100.0| 91.6261|  8.3739|       0|         0|             0|    Apto|\n",
    "\"\"\"\n",
    "\n",
    "dqi_v3 = dqi_v2.select(\"uf\", \"co_ibge\", \"municipio\", \"epi_week\", \"epi_year\", \"perc_missing\", \"perc_completude\", \"diff_2w\", \"diff_3w\", \"sum_miss\", \"completude\", \"tempestividade\", \"dqi\")\n",
    "dqi_v3 = dqi_v3.na.fill({'diff_2w': 0, 'diff_3w': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a42bd5f-3d1a-40dd-871e-79283b2d1f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "caminho_pasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e136c3e-9dbc-42fc-8691-43c89dd0acae",
   "metadata": {},
   "outputs": [],
   "source": [
    "caminho_pasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696bff89-8b6e-4e0d-b816-7ac7327fd33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_salvar = \"s3://fiocruz-datalake-bucket/\"+caminho_pasta\n",
    "path_salvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5732956e-a36b-471f-bc4b-8e86d01b7aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_salvar_dqi = aesop_dqi_report_folder+'semana_'+str(semana_folder)+\"/dqi.csv\"\n",
    "\n",
    "\n",
    "dqi_v3.toPandas().to_csv(path_salvar+\"/dqi.csv\",index=False)\n",
    "path_salvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28af5d7-7619-4d0d-af53-b2c01a7cf303",
   "metadata": {},
   "outputs": [],
   "source": [
    "%stop_session"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Glue PySpark",
   "language": "python",
   "name": "glue_pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "Python_Glue_Session",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
